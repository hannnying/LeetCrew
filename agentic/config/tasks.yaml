analyze_topic_performance_task:
  description: >
    Analyze raw topic stats to calculate normalized performance metrics such as accuracy,
    hint usage rate, and YouTube watch rate per topic, expressed as percentages.
  expected_output: >
    A dictionary where each key is a topic name (string), and each value is another dictionary containing the following float percentage metrics for that topic:
    - accuracy: percentage of questions solved correctly
    - hints_usage: percentage of questions where hints were used
    - youtube_watch_rate: percentage of questions where YouTube explanations were watched
    Example:
    {
      "topic_name": {
        "accuracy": float,            # Percentage of solved questions
        "hints_usage": float,         # Percentage of questions where hints were used
        "youtube_watch_rate": float   # Percentage of questions where YouTube videos were watched
      },
      ...
    }
  agent: performance_analyst


rank_weak_topics_task:
  description: >
    Given analyzed topic performance metrics, compute a combined weakness score for each topic
    based on accuracy, hint usage, and YouTube watch rates. Return a ranked list of the top N
    weakest topics with their scores.
  expected_output: >
    A list of dictionaries, where each dictionary represents a weak topic and contains:
    - topic (string): the name of the topic
    - score (float): the combined weakness score (higher means the topic needs more improvement)
    [
      {
        "topic": "topic_name",
        "score": float               # Combined weakness score (higher means weaker)
      },
      ...
    ]
  agent: performance_analyst
  

select_questions_task:
  description: >
    You are provided with two pieces of information:
    1. A list of weak topics that the user struggles with.
    2. A JSON knowledge base containing questions the user has not solved, along with their topics and difficulty.

    Your task is to select questions that are most relevant to the user's weak areas. 
    Only choose questions that have at least one topic overlapping with the weak topics list.
    Return a list of matching question slugs with associated metadata.
  expected_output: >
    A list of dictionaries, each containing the following fields:
    - question_id: the question identifier
    - difficulty: the difficulty level of the question
    - topics: a list of topics associated with the question
    Example:
    [
      {
        "slug": "two-sum",
        "topics": ["Array", "Hash Table"],
        "difficulty": "Easy"
      },
      ...
    ]
  agent: question_finder